## ðŸ“Š **Graph RAG with Neo4j â€“ Hands-on Training**  

---

## ðŸ† **Objectives**  
âœ… Understand RAG (Retrieval-Augmented Generation) and its importance  
âœ… Learn key concepts: embeddings, vectors, similarity search, cosine similarity, chunking, tokens  
âœ… Understand how RAG overcomes limitations like context length and domain knowledge  
âœ… Explore how Graph RAG integrates with Neo4j for better retrieval and generation  
âœ… Hands-on examples using Python, Neo4j, and OpenAI  
âœ… Expand Graph RAG to handle multi-modal data (images, videos)  
âœ… Compare SQL, NoSQL, and Graph databases (why and when to use Graph DB)  
âœ… Understand tokenization and its role in text processing  

---

## ðŸŒ **1. What is RAG (Retrieval-Augmented Generation)?**  

### ðŸ”Ž **Definition**  
RAG is an AI framework that combines **information retrieval** and **language generation** to produce more accurate and context-aware responses.  

### ðŸš€ **How RAG Works:**  
1. **Input:** User provides a query  
2. **Retrieval:** Relevant data is fetched from a knowledge base using embeddings and similarity search  
3. **Augmentation:** Retrieved data is added to the prompt  
4. **Generation:** LLM generates the final answer based on the augmented prompt  

---

### âœ… **Why RAG is Powerful**  
| Problem | How RAG Solves It |
|---------|--------------------|
| **Context Length Limit** | External knowledge base extends the available context |
| **Hallucination** | Grounding responses in real data reduces hallucination |
| **Domain Knowledge** | Embedding search helps include domain-specific information |
| **Real-Time Information** | Retrieval ensures the latest data is used |

---

### ðŸ† **Example:**  
**Without RAG:**  
ðŸ‘‰ *What is the capital of France?*  
â†’ "The capital of France is Paris."  

**With RAG:**  
ðŸ‘‰ *What is the latest news about France's elections?*  
â†’ RAG retrieves recent news and provides an updated answer.  

---

## ðŸ§  **2. Key Concepts**  

### ðŸ“Œ **Embeddings**  
- Mathematical representation of text or data in a multi-dimensional space.  
- Similar texts will have embeddings closer to each other.  
- Generated using models like **OpenAI, SentenceTransformers, HuggingFace**  

**Example:**  
ðŸ‘‰ Converts text to numerical form for similarity search.  
```python
from langchain.embeddings import OpenAIEmbeddings

embeddings = OpenAIEmbeddings()
text = "France is a country in Europe."
vector = embeddings.embed_query(text)
print(vector)  # Output: [0.12, -0.34, 0.87, ...]
```

---

### ðŸ“Œ **Vectors**  
- Numerical arrays representing embeddings.  
- Used to measure similarity between data points.  

**Example:**  
ðŸ‘‰ `"Paris is the capital of France"` â†’ `[0.12, -0.45, 0.98, -0.21, ...]`  
ðŸ‘‰ `"Berlin is the capital of Germany"` â†’ `[0.15, -0.43, 0.91, -0.20, ...]`  

---

### ðŸ“Œ **Similarity Search**  
- Process of finding the most relevant embeddings based on a similarity score.  
- Techniques:  
  - **Cosine Similarity**  
  - **Euclidean Distance**  

---

### ðŸ“Œ **Cosine Similarity**  
Measures the angle between two vectors.  
\[
\text{similarity}(A, B) = \frac{A \cdot B}{||A|| \times ||B||}
\]

**Example:**  
ðŸ‘‰ Measures how similar two texts are based on vector closeness.  
```python
from sklearn.metrics.pairwise import cosine_similarity
import numpy as np

vec1 = np.array([0.12, -0.45, 0.98])
vec2 = np.array([0.15, -0.43, 0.91])

similarity = cosine_similarity([vec1], [vec2])
print(similarity)  # Output: [[0.998]]
```

---

### ðŸ“Œ **Chunking**  
- Splitting large text into smaller parts for better embedding and retrieval.  

**Example:**  
ðŸ‘‰ Breaking down text to improve search.  
```python
from langchain.text_splitter import RecursiveCharacterTextSplitter

text = "Neo4j is a graph database that stores data as nodes and edges..."
splitter = RecursiveCharacterTextSplitter(chunk_size=50, chunk_overlap=10)
chunks = splitter.split_text(text)
print(chunks)  # ['Neo4j is a graph database...', 'database that stores...']
```

---

### ðŸ“Œ **Tokens**  
- Smallest unit of text processed by an LLM.  
- Example: `"Neo4j is powerful"` â†’ `["Neo4j", "is", "powerful"]`  

**Example:**  
ðŸ‘‰ Breaks text into tokens for processing.  
```python
from transformers import GPT2Tokenizer

tokenizer = GPT2Tokenizer.from_pretrained("gpt2")
tokens = tokenizer.encode("Neo4j is a graph database.")
print(tokens)  # Output: [6342, 318, 257, 20776, 5875, 13]
```

---

## ðŸ’¾ **3. SQL vs NoSQL vs Graph DB**  

| Type | Structure | Best Use Cases | Example |
|-------|-----------|----------------|---------|
| **SQL** | Tables (Rows & Columns) | Structured data, ACID compliance | MySQL, PostgreSQL |
| **NoSQL** | Key-Value, Document, Column | Flexible schema, large-scale data | MongoDB, Redis |
| **Graph DB** | Nodes & Edges | Complex relationships, relationship-first queries | Neo4j |

---

### âœ… **Why Graph DB Over SQL/NoSQL?**  
- **Natural for Relationships** â€“ Data with complex interconnections.  
- **Fast Traversals** â€“ Queries across connected nodes are faster.  
- **Flexibility** â€“ Schema-less structure handles dynamic data.  

**Example:**  
- SQL:  
ðŸ‘‰ `"Find all friends of John"` â€“ Needs multiple JOINs (slow).  
- Graph DB:  
ðŸ‘‰ `"MATCH (John)-[:FRIEND]->(friends) RETURN friends"` â€“ Direct relationship (fast).  

---

## ðŸ“š **4. How Graph RAG Works with Neo4j**  

### âœ… **Graph Structure in Neo4j**  
- **Nodes** â†’ Entities (documents, authors, keywords)  
- **Relationships** â†’ Contextual connections between nodes  

---

### **Step 1: Setup Neo4j Connection**  
ðŸ‘‰ Connects Python to Neo4j.  
```python
from neo4j import GraphDatabase

class GraphHandler:
    def __init__(self, uri, user, password):
        self.driver = GraphDatabase.driver(uri, auth=(user, password))

    def close(self):
        self.driver.close()
```

---

### **Step 2: Insert Data into Neo4j**  
ðŸ‘‰ Stores embeddings as nodes in Neo4j.  
```python
def create_node(tx, label, properties):
    query = f"CREATE (n:{label} {{ {', '.join(f'{k}: ${k}' for k in properties)} }})"
    tx.run(query, **properties)

handler = GraphHandler("bolt://localhost:7687", "neo4j", "password")
with handler.driver.session() as session:
    session.write_transaction(create_node, "Document", {
        "text": "Neo4j is a graph database...",
        "embedding": vector
    })
```

---

### **Step 3: Perform Similarity Search**  
ðŸ‘‰ Retrieves similar nodes using cosine similarity.  
```python
def search_similar_docs(tx, query_vector):
    query = """
    MATCH (d:Document)
    RETURN d.text, cosineSimilarity(d.embedding, $query_vector) AS score
    ORDER BY score DESC
    LIMIT 3
    """
    result = tx.run(query, query_vector=query_vector)
    return [record["d.text"] for record in result]

with handler.driver.session() as session:
    result = session.read_transaction(search_similar_docs, vector)
    print(result)
```

---

### **Step 4: Generate Response with LLM**  
ðŸ‘‰ Feeds retrieved data to LLM.  
```python
from langchain.llms import OpenAI

llm = OpenAI()
prompt = f"Using the following context:\n{result}\nExplain Neo4j."
response = llm(prompt)
print(response)
```

---

## ðŸŒŸ **5. Why Graph RAG is Better**  
| Problem | Solution in Graph RAG |
|---------|-----------------------|
| Context Length | Extends retrieval beyond token limits |
| Data Relationships | Graph-based connections improve contextual relevance |
| Real-Time Knowledge | Fast retrieval of the latest information |

---

## ðŸŽ¯ **6. Multi-Modal Graph RAG**  
ðŸ‘‰ Store embeddings for images/videos in Neo4j and search based on similarity.

---

# ðŸŒ **LangGraph â€“ Hands-On Training**  

---

## ðŸ† **Objectives**  
âœ… Understand LangGraph and its key concepts  
âœ… Explain how LangGraph enables multi-step workflows  
âœ… Create an example LangGraph-based RAG pipeline  
âœ… Handle memory, state, and complex branching in workflows  
âœ… Integrate LangGraph with Neo4j for Graph RAG  

---

## ðŸŒ **1. What is LangGraph?**  
LangGraph is a **graph-based framework** built on top of **LangChain** that enables the creation of **multi-step, multi-agent workflows** for LLM-based applications.  

---

### ðŸš€ **LangGraph = LangChain + State Management + Graph-Based Flow**  
1. **LangChain** â†’ Framework for building LLM-based applications  
2. **State Management** â†’ Maintains memory and context across multiple steps  
3. **Graph-Based Flow** â†’ Directed graph (DAG) model to control execution path  

---

### ðŸ’¡ **Why LangGraph Over LangChain?**  
| Feature | LangChain | LangGraph |
|---|---|---|
| **Single-step execution** | âœ… | âœ… |
| **Multi-step execution** | âŒ | âœ… |
| **Parallelism** | âŒ | âœ… |
| **Branching & Conditional Logic** | âŒ | âœ… |
| **Stateful Memory** | Limited | âœ… |
| **Event Handling** | âŒ | âœ… |

---

## ðŸ” **2. Key Concepts in LangGraph**  

---

### ðŸ“Œ **(i) Nodes**  
- Building blocks of a LangGraph workflow  
- Represents **steps** in the pipeline  
- Can be:  
  - LLM calls  
  - Embedding generation  
  - Data retrieval  
  - Similarity search  

âœ… **Example:**  
- Node 1 â†’ Generate embedding  
- Node 2 â†’ Search Neo4j  
- Node 3 â†’ Generate output  

---

### ðŸ“Œ **(ii) Edges**  
- Connect nodes together  
- Represent flow of data between steps  
- Can be **conditional** or **unconditional**  

âœ… **Example:**  
- If similarity > 0.8 â†’ Use result for augmentation  
- If similarity < 0.8 â†’ Search another source  

---

### ðŸ“Œ **(iii) State**  
- Shared memory across nodes  
- Tracks intermediate results  
- Supports complex reasoning  

âœ… **Example:**  
- Store query embeddings  
- Track search results  
- Pass retrieved documents to LLM  

---

### ðŸ“Œ **(iv) Branching**  
- Create different paths based on conditions  
- Handles **multi-hop reasoning**  
- Supports real-time adjustments  

âœ… **Example:**  
- If data is not found â†’ Perform web search  
- If data is found â†’ Augment response  

---

### ðŸ“Œ **(v) Parallel Execution**  
- Execute multiple nodes simultaneously  
- Improves efficiency and reduces latency  

âœ… **Example:**  
- Generate embeddings while searching Neo4j  
- Search multiple sources in parallel  

---

### ðŸ“Œ **(vi) Memory**  
- Stateful memory persists across nodes  
- Provides continuity and context retention  
- Avoids repetitive queries  

âœ… **Example:**  
- Track previous conversation history  
- Remember user preferences  

---

## ðŸ—ï¸ **3. Example: LangGraph-Based RAG with Neo4j**  

---

### âœ… **Step 1: Install Dependencies**  
```bash
pip install langchain langgraph neo4j openai
```

---

### âœ… **Step 2: Import Dependencies**  
```python
from langchain.embeddings import OpenAIEmbeddings
from langchain.chat_models import ChatOpenAI
from langgraph.graph import StateGraph, END
from langchain.schema import Document
from neo4j import GraphDatabase
```

---

### âœ… **Step 3: Define State**  
- Define memory for sharing data between nodes  

```python
class RAGState:
    query: str
    retrieved_docs: list
    final_answer: str
```

---

### âœ… **Step 4: Set Up Neo4j Connection**  
```python
handler = GraphDatabase.driver("bolt://localhost:7687", auth=("neo4j", "password"))
```

---

### âœ… **Step 5: Define Node 1 â€“ Generate Embedding**  
```python
embeddings = OpenAIEmbeddings()

def generate_embedding(state):
    query = state.query
    vector = embeddings.embed_query(query)
    return {"query_vector": vector}
```

---

### âœ… **Step 6: Define Node 2 â€“ Search Neo4j**  
```python
def search_neo4j(state):
    query_vector = state["query_vector"]
    
    cypher_query = """
    MATCH (d:Document)
    RETURN d.text, 
           cosineSimilarity(d.embedding, $query_vector) AS score
    ORDER BY score DESC
    LIMIT 3
    """
    
    with handler.session() as session:
        results = session.run(cypher_query, query_vector=query_vector)
        docs = [record["d.text"] for record in results]
    
    return {"retrieved_docs": docs}
```

---

### âœ… **Step 7: Define Node 3 â€“ Generate Answer**  
```python
llm = ChatOpenAI()

def generate_answer(state):
    context = "\n".join(state["retrieved_docs"])
    prompt = f"Context:\n{context}\n\nQuestion: {state['query']}\nAnswer:"
    
    response = llm.predict(prompt)
    
    return {"final_answer": response}
```

---

### âœ… **Step 8: Build Graph**  
```python
graph = StateGraph(RAGState)

# Add nodes
graph.add_node("generate_embedding", generate_embedding)
graph.add_node("search_neo4j", search_neo4j)
graph.add_node("generate_answer", generate_answer)

# Define edges
graph.add_edge("generate_embedding", "search_neo4j")
graph.add_edge("search_neo4j", "generate_answer")
graph.add_edge("generate_answer", END)

# Set entry point
graph.set_entry_point("generate_embedding")

# Compile graph
app = graph.compile()
```

---

### âœ… **Step 9: Execute Workflow**  
```python
query = "What is Graph RAG?"
state = RAGState(query=query)

# Run pipeline
result = app.invoke(state)
print(result["final_answer"])
```

---

## ðŸ§  **4. How LangGraph Handles Complex Logic**  
âœ… **Multi-hop Reasoning:**  
- Search graph â†’ Augment with context â†’ Generate response  

âœ… **Real-time Adjustments:**  
- Handle missing context dynamically  

âœ… **Efficient Retrieval:**  
- Search multiple sources simultaneously  

âœ… **State Preservation:**  
- LLM maintains context across nodes  

---

## ðŸŒŸ **5. Why LangGraph + Graph RAG = ðŸ’ª**  
| Challenge | Solution |
|---|---|
| Context length limits | External knowledge retrieval using graph search |
| Hallucination | Fact-based generation using grounded data |
| Complex queries | Multi-hop search across graph nodes |
| Real-time updates | Graph-based search handles dynamic changes |
| Data relationships | Graph model preserves entity relationships |

---

## ðŸŽ¯ **6. Multi-Modal Expansion**  
âœ… Text + Images + Videos + Audio  
âœ… Handle diverse data types using vector embeddings  

### âœ… **Example:**  
1. Text â†’ OpenAI embeddings  
2. Image â†’ CLIP embeddings  
3. Audio â†’ Whisper embeddings  

---

### âœ… **Example Code:**  
```python
from langchain.embeddings import CLIPEmbeddings

clip = CLIPEmbeddings()
image_vector = clip.embed_image("path/to/image.jpg")
```

---

## ðŸš€ **7. Why LangGraph Over Traditional Pipelines**  
âœ… Easy to build complex workflows  
âœ… Better branching and error handling  
âœ… Parallel execution reduces latency  
âœ… State management improves consistency  

---

## ðŸ† **8. Summary**  
ðŸš€ LangGraph + Graph RAG = **Best of Both Worlds**  
ðŸ’¡ Multi-step, Multi-hop, Parallel Reasoning  
ðŸ”Ž Neo4j provides **structured graph search**  
ðŸ¤– OpenAI provides **high-quality text generation**  

---

## ðŸ™Œ **Q&A**  

