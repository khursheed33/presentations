# ðŸ“Š **Graph RAG with Neo4j â€“ Hands-on Training**  

---

## ðŸ† **Objectives**  
âœ… Understand RAG (Retrieval-Augmented Generation) and its importance  
âœ… Learn key concepts: embeddings, vectors, similarity search, cosine similarity, chunking, tokens  
âœ… Understand how RAG overcomes limitations like context length and domain knowledge  
âœ… Explore how Graph RAG integrates with Neo4j for better retrieval and generation  
âœ… Hands-on examples using Python, Neo4j, and OpenAI  
âœ… Expand Graph RAG to handle multi-modal data (images, videos)  

---

## ðŸŒ **What is RAG (Retrieval-Augmented Generation)?**  

### ðŸ”Ž **Definition**  
- RAG is an AI framework that combines **information retrieval** and **language generation** to produce more accurate and context-aware responses.  
- It works by retrieving relevant information from a knowledge base and injecting it into the LLM's prompt to enhance response quality.  

---

### ðŸš€ **How RAG Works:**  
1. **Input:** User provides a query  
2. **Retrieval:** Relevant data is fetched from a knowledge base using embeddings and similarity search  
3. **Augmentation:** Retrieved data is added to the prompt  
4. **Generation:** LLM generates the final answer based on the augmented prompt  

---

### âœ… **Why RAG is Powerful**  
| Problem | How RAG Solves It |
|---------|--------------------|
| **Context Length Limit** | External knowledge base extends the available context |
| **Hallucination** | Grounding responses in real data reduces hallucination |
| **Domain Knowledge** | Embedding search helps include domain-specific information |
| **Real-Time Information** | Retrieval ensures the latest data is used |

---

### ðŸ† **Example:**  
**Without RAG:**  
ðŸ‘‰ *What is the capital of France?*  
â†’ "The capital of France is Paris."  

**With RAG:**  
ðŸ‘‰ *What is the latest news about France's elections?*  
â†’ RAG retrieves recent news and provides an updated answer.  

---

## ðŸ§  **Key Concepts**  

### ðŸ“Œ **Embeddings**  
- Mathematical representation of text or data in a multi-dimensional space.  
- Similar texts will have embeddings closer to each other.  

**Example:**  
```python
from langchain.embeddings import OpenAIEmbeddings

embeddings = OpenAIEmbeddings()
text = "France is a country in Europe."
vector = embeddings.embed_query(text)
print(vector)  # Output: [0.12, -0.34, 0.87, ...]
```

âœ… *This creates a vector representation of the text to enable similarity search.*  

---

### ðŸ“Œ **Vectors**  
- Numerical arrays representing embeddings.  
- Used to measure similarity between data points.  

**Example:**  
ðŸ‘‰ `"Paris is the capital of France"` â†’ `[0.12, -0.45, 0.98, -0.21, ...]`  
ðŸ‘‰ `"Berlin is the capital of Germany"` â†’ `[0.15, -0.43, 0.91, -0.20, ...]`  

âœ… *Vectors represent the semantic meaning of text, allowing for comparison.*  

---

### ðŸ“Œ **Similarity Search**  
- Process of finding the most relevant embeddings based on a similarity score.  
- Techniques:  
  - **Cosine Similarity**  
  - **Euclidean Distance**  

**Example:**  
```python
from sklearn.metrics.pairwise import cosine_similarity
import numpy as np

vec1 = np.array([0.12, -0.45, 0.98])
vec2 = np.array([0.15, -0.43, 0.91])

similarity = cosine_similarity([vec1], [vec2])
print(similarity)  # Output: [[0.998]]
```

âœ… *Higher similarity score = more similar content.*  

---

### ðŸ“Œ **Cosine Similarity**  
Measures the angle between two vectors.  
\[
\text{similarity}(A, B) = \frac{A \cdot B}{||A|| \times ||B||}
\]

âœ… *Cosine similarity is commonly used because it measures semantic similarity accurately.*  

---

### ðŸ“Œ **Chunking**  
- Splitting large text into smaller parts for better embedding and retrieval.  

**Example:**  
```python
from langchain.text_splitter import RecursiveCharacterTextSplitter

text = "Neo4j is a graph database that stores data as nodes and edges..."
splitter = RecursiveCharacterTextSplitter(chunk_size=50, chunk_overlap=10)
chunks = splitter.split_text(text)
print(chunks)
```

âœ… *Chunking allows handling large documents efficiently.*  

---

### ðŸ“Œ **Tokens**  
- Smallest unit of text processed by an LLM.  
- Example: `"Neo4j is powerful"` â†’ `["Neo4j", "is", "powerful"]`  

**Example:**  
```python
from transformers import GPT2Tokenizer

tokenizer = GPT2Tokenizer.from_pretrained("gpt2")
tokens = tokenizer.encode("Neo4j is a graph database.")
print(tokens)  # Output: [6342, 318, 257, 20776, 5875, 13]
```

âœ… *Tokenization helps LLM understand and process text.*  

---

## ðŸ’¾ **SQL vs NoSQL vs Graph DB**  

| Feature | SQL (Relational) | NoSQL (Document-based) | Graph DB (Neo4j) |
|---------|-------------------|------------------------|------------------|
| **Data Structure** | Tables (Rows & Columns) | Collections & Documents | Nodes & Relationships |
| **Use Case** | Financial data, structured data | Unstructured data | Connected data |
| **Performance** | Slower for complex joins | Fast for large data | Fast for connected data |
| **Schema** | Rigid | Flexible | Flexible |
| **Example** | MySQL, PostgreSQL | MongoDB, Firebase | Neo4j, ArangoDB |

âœ… *Graph DB excels in handling relationships between data points.*  

---

## ðŸ“š **How Graph RAG Works with Neo4j**  

### âœ… **Graph Structure in Neo4j**  
- **Nodes** â†’ Entities (documents, authors, keywords)  
- **Relationships** â†’ Contextual connections between nodes  

---

### **Step 1: Setup Neo4j Connection**  
```python
from neo4j import GraphDatabase

class GraphHandler:
    def __init__(self, uri, user, password):
        self.driver = GraphDatabase.driver(uri, auth=(user, password))

    def close(self):
        self.driver.close()
```

âœ… *This sets up the connection to a Neo4j instance.*  

---

### **Step 2: Insert Data into Neo4j**  
```python
def create_node(tx, label, properties):
    query = f"CREATE (n:{label} {{ {', '.join(f'{k}: ${k}' for k in properties)} }})"
    tx.run(query, **properties)

handler = GraphHandler("bolt://localhost:7687", "neo4j", "password")
with handler.driver.session() as session:
    session.write_transaction(create_node, "Document", {
        "text": "Neo4j is a graph database...",
        "embedding": vector
    })
```

âœ… *This creates a new document node with embeddings.*  

---

### **Step 3: Perform Similarity Search**  
```python
def search_similar_docs(tx, query_vector):
    query = """
    MATCH (d:Document)
    RETURN d.text, cosineSimilarity(d.embedding, $query_vector) AS score
    ORDER BY score DESC
    LIMIT 3
    """
    result = tx.run(query, query_vector=query_vector)
    return [record["d.text"] for record in result]

with handler.driver.session() as session:
    result = session.read_transaction(search_similar_docs, vector)
    print(result)
```

âœ… *This retrieves the most relevant documents.*  

---

### **Step 4: Generate Response with LLM**  
```python
from langchain.llms import OpenAI

llm = OpenAI()
prompt = f"Using the following context:\n{result}\nExplain Neo4j."
response = llm(prompt)
print(response)
```

âœ… *This generates an answer based on retrieved context.*  

---

## ðŸŒŸ **Why Graph RAG is Better**  
- Faster retrieval  
- Better contextual understanding  
- Stronger relationship-based search  
- Handles real-time data better  

---

# ðŸŒ **LangGraph â€“ Hands-On Training**  

---

## ðŸ† **Objectives**  
âœ… Understand LangGraph and its key concepts  
âœ… Explain how LangGraph enables multi-step workflows  
âœ… Create an example LangGraph-based RAG pipeline  
âœ… Handle memory, state, and complex branching in workflows  
âœ… Integrate LangGraph with Neo4j for Graph RAG  

---

## ðŸŒ **1. What is LangGraph?**  
LangGraph is a **graph-based framework** built on top of **LangChain** that enables the creation of **multi-step, multi-agent workflows** for LLM-based applications.  

---

### ðŸš€ **LangGraph = LangChain + State Management + Graph-Based Flow**  
1. **LangChain** â†’ Framework for building LLM-based applications  
2. **State Management** â†’ Maintains memory and context across multiple steps  
3. **Graph-Based Flow** â†’ Directed graph (DAG) model to control execution path  

---

### ðŸ’¡ **Why LangGraph Over LangChain?**  
| Feature | LangChain | LangGraph |
|---|---|---|
| **Single-step execution** | âœ… | âœ… |
| **Multi-step execution** | âŒ | âœ… |
| **Parallelism** | âŒ | âœ… |
| **Branching & Conditional Logic** | âŒ | âœ… |
| **Stateful Memory** | Limited | âœ… |
| **Event Handling** | âŒ | âœ… |

---

## ðŸ” **2. Key Concepts in LangGraph**  

---

### ðŸ“Œ **(i) Nodes**  
- Building blocks of a LangGraph workflow  
- Represents **steps** in the pipeline  
- Can be:  
  - LLM calls  
  - Embedding generation  
  - Data retrieval  
  - Similarity search  

âœ… **Example:**  
- Node 1 â†’ Generate embedding  
- Node 2 â†’ Search Neo4j  
- Node 3 â†’ Generate output  

---

### ðŸ“Œ **(ii) Edges**  
- Connect nodes together  
- Represent flow of data between steps  
- Can be **conditional** or **unconditional**  

âœ… **Example:**  
- If similarity > 0.8 â†’ Use result for augmentation  
- If similarity < 0.8 â†’ Search another source  

---

### ðŸ“Œ **(iii) State**  
- Shared memory across nodes  
- Tracks intermediate results  
- Supports complex reasoning  

âœ… **Example:**  
- Store query embeddings  
- Track search results  
- Pass retrieved documents to LLM  

---

### ðŸ“Œ **(iv) Branching**  
- Create different paths based on conditions  
- Handles **multi-hop reasoning**  
- Supports real-time adjustments  

âœ… **Example:**  
- If data is not found â†’ Perform web search  
- If data is found â†’ Augment response  

---

### ðŸ“Œ **(v) Parallel Execution**  
- Execute multiple nodes simultaneously  
- Improves efficiency and reduces latency  

âœ… **Example:**  
- Generate embeddings while searching Neo4j  
- Search multiple sources in parallel  

---

### ðŸ“Œ **(vi) Memory**  
- Stateful memory persists across nodes  
- Provides continuity and context retention  
- Avoids repetitive queries  

âœ… **Example:**  
- Track previous conversation history  
- Remember user preferences  

---

## ðŸ—ï¸ **3. Example: LangGraph-Based RAG with Neo4j**  

---

### âœ… **Step 1: Install Dependencies**  
```bash
pip install langchain langgraph neo4j openai
```

---

### âœ… **Step 2: Import Dependencies**  
```python
from langchain.embeddings import OpenAIEmbeddings
from langchain.chat_models import ChatOpenAI
from langgraph.graph import StateGraph, END
from langchain.schema import Document
from neo4j import GraphDatabase
```

---

### âœ… **Step 3: Define State**  
- Define memory for sharing data between nodes  

```python
class RAGState:
    query: str
    retrieved_docs: list
    final_answer: str
```

---

### âœ… **Step 4: Set Up Neo4j Connection**  
```python
handler = GraphDatabase.driver("bolt://localhost:7687", auth=("neo4j", "password"))
```

---

### âœ… **Step 5: Define Node 1 â€“ Generate Embedding**  
```python
embeddings = OpenAIEmbeddings()

def generate_embedding(state):
    query = state.query
    vector = embeddings.embed_query(query)
    return {"query_vector": vector}
```

---

### âœ… **Step 6: Define Node 2 â€“ Search Neo4j**  
```python
def search_neo4j(state):
    query_vector = state["query_vector"]
    
    cypher_query = """
    MATCH (d:Document)
    RETURN d.text, 
           cosineSimilarity(d.embedding, $query_vector) AS score
    ORDER BY score DESC
    LIMIT 3
    """
    
    with handler.session() as session:
        results = session.run(cypher_query, query_vector=query_vector)
        docs = [record["d.text"] for record in results]
    
    return {"retrieved_docs": docs}
```

---

### âœ… **Step 7: Define Node 3 â€“ Generate Answer**  
```python
llm = ChatOpenAI()

def generate_answer(state):
    context = "\n".join(state["retrieved_docs"])
    prompt = f"Context:\n{context}\n\nQuestion: {state['query']}\nAnswer:"
    
    response = llm.predict(prompt)
    
    return {"final_answer": response}
```

---

### âœ… **Step 8: Build Graph**  
```python
graph = StateGraph(RAGState)

# Add nodes
graph.add_node("generate_embedding", generate_embedding)
graph.add_node("search_neo4j", search_neo4j)
graph.add_node("generate_answer", generate_answer)

# Define edges
graph.add_edge("generate_embedding", "search_neo4j")
graph.add_edge("search_neo4j", "generate_answer")
graph.add_edge("generate_answer", END)

# Set entry point
graph.set_entry_point("generate_embedding")

# Compile graph
app = graph.compile()
```

---

### âœ… **Step 9: Execute Workflow**  
```python
query = "What is Graph RAG?"
state = RAGState(query=query)

# Run pipeline
result = app.invoke(state)
print(result["final_answer"])
```

---

## ðŸ§  **4. How LangGraph Handles Complex Logic**  
âœ… **Multi-hop Reasoning:**  
- Search graph â†’ Augment with context â†’ Generate response  

âœ… **Real-time Adjustments:**  
- Handle missing context dynamically  

âœ… **Efficient Retrieval:**  
- Search multiple sources simultaneously  

âœ… **State Preservation:**  
- LLM maintains context across nodes  

---

## ðŸŒŸ **5. Why LangGraph + Graph RAG = ðŸ’ª**  
| Challenge | Solution |
|---|---|
| Context length limits | External knowledge retrieval using graph search |
| Hallucination | Fact-based generation using grounded data |
| Complex queries | Multi-hop search across graph nodes |
| Real-time updates | Graph-based search handles dynamic changes |
| Data relationships | Graph model preserves entity relationships |

---

## ðŸŽ¯ **6. Multi-Modal Expansion**  
âœ… Text + Images + Videos + Audio  
âœ… Handle diverse data types using vector embeddings  

### âœ… **Example:**  
1. Text â†’ OpenAI embeddings  
2. Image â†’ CLIP embeddings  
3. Audio â†’ Whisper embeddings  

---

### âœ… **Example Code:**  
```python
from langchain.embeddings import CLIPEmbeddings

clip = CLIPEmbeddings()
image_vector = clip.embed_image("path/to/image.jpg")
```

---

## ðŸš€ **7. Why LangGraph Over Traditional Pipelines**  
âœ… Easy to build complex workflows  
âœ… Better branching and error handling  
âœ… Parallel execution reduces latency  
âœ… State management improves consistency  

---

## ðŸ† **8. Summary**  
ðŸš€ LangGraph + Graph RAG = **Best of Both Worlds**  
ðŸ’¡ Multi-step, Multi-hop, Parallel Reasoning  
ðŸ”Ž Neo4j provides **structured graph search**  
ðŸ¤– OpenAI provides **high-quality text generation**  

---

## ðŸ™Œ **Q&A**  

